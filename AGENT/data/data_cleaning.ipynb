{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on '1@localhost' ([Errno -2] Name or service not known)\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pymysql/connections.py:649\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    835\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    837\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/socket.py:967\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    966\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    968\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3297\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3277\u001b[0m \n\u001b[1;32m   3278\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:625\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pymysql/connections.py:361\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pymysql/connections.py:716\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on '1@localhost' ([Errno -2] Name or service not known)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 107\u001b[0m\n\u001b[1;32m      9\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmysql+pymysql://root:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@localhost/tawos\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mSELECT\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m    p.Name AS project_name,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124m;\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 107\u001b[0m df_query \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m df_query\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/io/sql.py:704\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    701\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    707\u001b[0m             sql,\n\u001b[1;32m    708\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    715\u001b[0m         )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/io/sql.py:906\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m adbc \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc_driver_manager.dbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc\u001b[38;5;241m.\u001b[39mConnection):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pandas/io/sql.py:1636\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[0;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[0;32m-> 1636\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3273\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3252\u001b[0m \n\u001b[1;32m   3253\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3270\u001b[0m \n\u001b[1;32m   3271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2436\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    148\u001b[0m             err, dialect, engine\n\u001b[1;32m    149\u001b[0m         )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3297\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3277\u001b[0m \n\u001b[1;32m   3278\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1267\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/pool/base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/sqlalchemy/engine/default.py:625\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pymysql/connections.py:361\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/pymysql/connections.py:716\u001b[0m, in \u001b[0;36mConnection.connect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m    715\u001b[0m         \u001b[38;5;28mprint\u001b[39m(exc\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# But raising AssertionError hides original error.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# So just reraise it.\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on '1@localhost' ([Errno -2] Name or service not known)\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "# Format: mysql+pymysql://user:password@host/database\n",
    "password = urllib.parse.quote_plus(os.environ['MYSQL_PASSWORD'])\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://root:{password}@localhost/tawos\"\n",
    ")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    p.Name AS project_name,\n",
    "    p.Description AS project_description,\n",
    "\n",
    "    r.Name AS repository_name,\n",
    "    r.Description AS repository_description,\n",
    "\n",
    "    s.ID AS sprint_id,\n",
    "    s.JiraID AS sprint_jira_id,\n",
    "    s.Name AS sprint_name,\n",
    "    s.State AS sprint_state,\n",
    "    s.Start_Date AS sprint_start_date,\n",
    "    s.End_Date AS sprint_end_date,\n",
    "    s.Activated_Date AS sprint_activated_date,\n",
    "    s.Complete_Date AS sprint_complete_date,\n",
    "    s.Project_ID AS sprint_project_id,\n",
    "\n",
    "    i.ID AS issue_id,\n",
    "    i.Jira_ID AS issue_jira_id,\n",
    "    i.Issue_Key AS issue_issue_key,\n",
    "    i.URL AS issue_url,\n",
    "    i.Title AS issue_title,\n",
    "    i.Description AS issue_description,\n",
    "    i.Description_Text AS issue_description_text,\n",
    "    i.Description_Code AS issue_description_code,\n",
    "    i.Type AS issue_type,\n",
    "    i.Priority AS issue_priority,\n",
    "    i.Status AS issue_status,\n",
    "    i.Resolution AS issue_resolution,\n",
    "    i.Creation_Date AS issue_creation_date,\n",
    "    i.Estimation_Date AS issue_estimation_date,\n",
    "    i.Resolution_Date AS issue_resolution_date,\n",
    "    i.Last_Updated AS issue_last_updated,\n",
    "    i.Story_Point AS issue_story_point,\n",
    "    i.Timespent AS issue_timespent,\n",
    "    i.In_Progress_Minutes AS issue_in_progress_minutes,\n",
    "    i.Total_Effort_Minutes AS issue_total_effort_minutes,\n",
    "    i.Resolution_Time_Minutes AS issue_resolution_time_minutes,\n",
    "    i.Title_Changed_After_Estimation AS issue_title_changed_after_estimation,\n",
    "    i.Description_Changed_After_Estimation AS issue_description_changed_after_estimation,\n",
    "    i.Story_Point_Changed_After_Estimation AS issue_story_point_changed_after_estimation,\n",
    "    i.Pull_Request_URL AS issue_pull_request_url,\n",
    "    i.Creator_ID AS issue_creator_id,\n",
    "    i.Reporter_ID AS issue_reporter_id,\n",
    "    i.Assignee_ID AS issue_assignee_id,\n",
    "    i.Project_ID AS issue_project_id,\n",
    "    i.Sprint_ID AS issue_sprint_id,\n",
    "\n",
    "    -- JSON_ARRAYAGG for comments\n",
    "    (\n",
    "      SELECT JSON_ARRAYAGG(\n",
    "        JSON_OBJECT(\n",
    "          'ID', c.ID,\n",
    "          'Comment', c.Comment,\n",
    "          'Comment_Text', c.Comment_Text,\n",
    "          'Comment_Code', c.Comment_Code,\n",
    "          'Creation_Date', c.Creation_Date,\n",
    "          'Author_ID', c.Author_ID\n",
    "        )\n",
    "      )\n",
    "      FROM Comment c\n",
    "      WHERE c.Issue_ID = i.ID\n",
    "    ) AS comments,\n",
    "\n",
    "    -- JSON_ARRAYAGG for change logs\n",
    "    (\n",
    "      SELECT JSON_ARRAYAGG(\n",
    "        JSON_OBJECT(\n",
    "          'ID', ch.ID,\n",
    "          'Field', ch.Field,\n",
    "          'From_Value', ch.From_Value,\n",
    "          'To_Value', ch.To_Value,\n",
    "          'From_String', ch.From_String,\n",
    "          'To_String', ch.To_String,\n",
    "          'Change_Type', ch.Change_Type,\n",
    "          'Creation_Date', ch.Creation_Date,\n",
    "          'Author_ID', ch.Author_ID\n",
    "        )\n",
    "      )\n",
    "      FROM Change_Log ch\n",
    "      WHERE ch.Issue_ID = i.ID\n",
    "    ) AS change_logs\n",
    "\n",
    "FROM Project p\n",
    "LEFT JOIN Repository r\n",
    "    ON p.Repository_ID = r.ID\n",
    "LEFT JOIN Issue i\n",
    "    ON i.Project_ID = p.ID\n",
    "LEFT JOIN Sprint s\n",
    "    ON i.Sprint_ID = s.ID\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "df_query = pd.read_sql(query, con=engine)\n",
    "df_query.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns:\n",
      "['project_name', 'project_description', 'repository_name', 'repository_description', 'sprint_name', 'sprint_state', 'sprint_start_date', 'sprint_end_date', 'sprint_activated_date', 'sprint_complete_date', 'issue_issue_key', 'issue_url', 'issue_title', 'issue_description', 'issue_description_text', 'issue_description_code', 'issue_type', 'issue_priority', 'issue_status', 'issue_resolution', 'issue_creation_date', 'issue_estimation_date', 'issue_resolution_date', 'issue_last_updated', 'issue_story_point', 'issue_timespent', 'issue_in_progress_minutes', 'issue_total_effort_minutes', 'issue_resolution_time_minutes', 'issue_title_changed_after_estimation', 'issue_description_changed_after_estimation', 'issue_story_point_changed_after_estimation', 'issue_pull_request_url', 'comments', 'change_logs']\n",
      "\n",
      "Sample data:\n",
      "   project_name                                project_description  \\\n",
      "24    Spring XD  Spring XD makes it easy to solve common big da...   \n",
      "25    Spring XD  Spring XD makes it easy to solve common big da...   \n",
      "26    Spring XD  Spring XD makes it easy to solve common big da...   \n",
      "27    Spring XD  Spring XD makes it easy to solve common big da...   \n",
      "28    Spring XD  Spring XD makes it easy to solve common big da...   \n",
      "\n",
      "   repository_name                             repository_description  \\\n",
      "24          Spring  The Spring Framework is an application framewo...   \n",
      "25          Spring  The Spring Framework is an application framewo...   \n",
      "26          Spring  The Spring Framework is an application framewo...   \n",
      "27          Spring  The Spring Framework is an application framewo...   \n",
      "28          Spring  The Spring Framework is an application framewo...   \n",
      "\n",
      "   sprint_name sprint_state    sprint_start_date      sprint_end_date  \\\n",
      "24   Sprint 68       CLOSED  2016-02-16 00:38:45  2016-02-26 08:34:00   \n",
      "25   Sprint 68       CLOSED  2016-02-16 00:38:45  2016-02-26 08:34:00   \n",
      "26   Sprint 68       CLOSED  2016-02-16 00:38:45  2016-02-26 08:34:00   \n",
      "27   Sprint 68       CLOSED  2016-02-16 00:38:45  2016-02-26 08:34:00   \n",
      "28   Sprint 68       CLOSED  2016-02-16 00:38:45  2016-02-26 08:34:00   \n",
      "\n",
      "   sprint_activated_date sprint_complete_date  ... issue_timespent  \\\n",
      "24                   NaT  2016-02-26 16:32:19  ...             NaN   \n",
      "25                   NaT  2016-02-26 16:32:19  ...             NaN   \n",
      "26                   NaT  2016-02-26 16:32:19  ...             NaN   \n",
      "27                   NaT  2016-02-26 16:32:19  ...             NaN   \n",
      "28                   NaT  2016-02-26 16:32:19  ...             NaN   \n",
      "\n",
      "   issue_in_progress_minutes issue_total_effort_minutes  \\\n",
      "24                      13.0                      172.0   \n",
      "25                      49.0                     1915.0   \n",
      "26                    1585.0                     3066.0   \n",
      "27                       0.0                        0.0   \n",
      "28                       0.0                     8290.0   \n",
      "\n",
      "   issue_resolution_time_minutes issue_title_changed_after_estimation  \\\n",
      "24                         194.0                                    0   \n",
      "25                        5039.0                                    0   \n",
      "26                        4625.0                                    1   \n",
      "27                       10524.0                                    0   \n",
      "28                       13482.0                                    0   \n",
      "\n",
      "   issue_description_changed_after_estimation  \\\n",
      "24                                          0   \n",
      "25                                          0   \n",
      "26                                          0   \n",
      "27                                          0   \n",
      "28                                          0   \n",
      "\n",
      "   issue_story_point_changed_after_estimation  \\\n",
      "24                                          0   \n",
      "25                                          0   \n",
      "26                                          0   \n",
      "27                                          0   \n",
      "28                                          0   \n",
      "\n",
      "                               issue_pull_request_url  \\\n",
      "24  https://github.com/spring-projects/spring-xd/p...   \n",
      "25  https://github.com/spring-projects/spring-xd/p...   \n",
      "26  https://github.com/spring-projects/spring-xd/p...   \n",
      "27                                                      \n",
      "28  https://github.com/spring-projects/spring-xd/p...   \n",
      "\n",
      "                                             comments  \\\n",
      "24                                                 []   \n",
      "25                                                 []   \n",
      "26                                                 []   \n",
      "27  [{'ID': 4455, 'Comment': 'Hi [~<USER>: Latest ...   \n",
      "28  [{'ID': 4456, 'Comment': 'The property is not ...   \n",
      "\n",
      "                                          change_logs  \n",
      "24  [{'ID': 97, 'Field': 'Link', 'To_Value': 'XD-2...  \n",
      "25  [{'ID': 108, 'Field': 'Link', 'To_Value': 'INT...  \n",
      "26  [{'ID': 118, 'Field': 'Epic Link', 'To_Value':...  \n",
      "27  [{'ID': 130, 'Field': 'Fix Version', 'To_Value...  \n",
      "28  [{'ID': 134, 'Field': 'Fix Version', 'To_Value...  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df_query\n",
    "# Convert JSON columns to Python objects\n",
    "df['comments'] = df['comments'].apply(lambda x: json.loads(x) if x else [])\n",
    "df['change_logs'] = df['change_logs'].apply(lambda x: json.loads(x) if x else [])\n",
    "\n",
    "# Drop columns that are primary/foreign keys (ending with '_id')\n",
    "columns_to_drop = [col for col in df.columns if col.endswith('_id')]\n",
    "#drop rows with none sprint_name\n",
    "df = df.dropna(subset=['sprint_name'])\n",
    "\n",
    "df_explore = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Print the remaining columns and a few rows of data for exploration\n",
    "print(\"Remaining columns:\")\n",
    "print(df_explore.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(df_explore.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marc\\Desktop\\AgenticRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Qwen/Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Qwen/Qwen2.5-1.5B-Instruct for text generation\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic sprint goals from issue descriptions\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Use the Qwen2.5-3B-Instruct model as specified\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "# Set up the model and tokenizer\n",
    "print(f\"Loading {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print(f\"Successfully loaded {model_name} for text generation\")\n",
    "\n",
    "def generate_sprint_goal(issue_descriptions, max_length=150):\n",
    "    \"\"\"\n",
    "    Generate a synthetic sprint goal based on a collection of issue descriptions.\n",
    "    \n",
    "    Args:\n",
    "        issue_descriptions (str): Combined issue descriptions from a sprint\n",
    "        max_length (int): Maximum token length for the generated text\n",
    "        \n",
    "    Returns:\n",
    "        str: A synthetic sprint goal\n",
    "    \"\"\"\n",
    "    # Truncate issue descriptions if they are too long to avoid token limits\n",
    "    truncated_descriptions = issue_descriptions[:2000] + \"...\" if len(issue_descriptions) > 2000 else issue_descriptions\n",
    "    \n",
    "    # Format as a message list for Qwen models (as per Hugging Face documentation)\n",
    "    prompt = f\"\"\"Based on the following issues in our sprint backlog, create a clear and concise sprint goal.\n",
    "\n",
    "    FORMAT YOUR RESPONSE EXACTLY AS:\n",
    "    **Sprint Goal:** [your concise sprint goal here]\n",
    "\n",
    "    DO NOT include any explanations, introductions, conclusions or additional notes.\n",
    "    Issues:\n",
    "    {truncated_descriptions}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You help create precise sprint goals for development teams.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # Generate the sprint goal\n",
    "    try:\n",
    "        # Apply the chat template to format messages for the model\n",
    "        input_text = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "        \n",
    "        # Determine which device the model is actually using\n",
    "        # Get the device of the first parameter of the model\n",
    "        model_device = next(model.parameters()).device\n",
    "        \n",
    "        # Move input_text to the same device as the model\n",
    "        input_text = input_text.to(model_device)\n",
    "        \n",
    "        # Generate response\n",
    "        outputs = model.generate(\n",
    "            input_text,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "        \n",
    "        # Decode only the newly generated tokens (not the prompt)\n",
    "        generated_text = tokenizer.decode(outputs[0][input_text.shape[1]:], skip_special_tokens=True).strip()\n",
    "        \n",
    "        # Clean up the response - remove any introductory text\n",
    "        sprint_goal = generated_text\n",
    "\n",
    "        # Extract the content after \"**Sprint Goal:**\" if present\n",
    "        sprint_goal_marker = \"**Sprint Goal:**\"\n",
    "        if sprint_goal_marker in sprint_goal:\n",
    "            sprint_goal = sprint_goal.split(sprint_goal_marker, 1)[1].strip()\n",
    "\n",
    "        return sprint_goal\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating sprint goal: {e}\")\n",
    "        return \"Improve system functionality and resolve critical issues.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sprints: 2945\n",
      "\n",
      "Sample of sprints:\n",
      "                     sprint_name                 project_name sprint_state  \\\n",
      "0       $.krypton - 6.3.1 part 2     Atlassian Software Cloud       CLOSED   \n",
      "1  0 Blast off - Mar 13-17 - SYD  Atlassian Confluence Server       FUTURE   \n",
      "2                             10        Hyperledger Indy Node       CLOSED   \n",
      "3            10-Annamite range 2   Atlassian Confluence Cloud       CLOSED   \n",
      "4                       10tative     Atlassian Software Cloud       CLOSED   \n",
      "\n",
      "     sprint_start_date      sprint_end_date  issue_count  \\\n",
      "0  2013-08-26 00:37:12  2013-09-09 00:37:00           10   \n",
      "1                 None                 None            1   \n",
      "2  2017-08-03 08:00:32  2017-08-16 08:00:00           29   \n",
      "3  2015-05-08 03:12:00  2015-05-15 03:12:00            3   \n",
      "4  2012-06-18 01:51:56  2012-07-02 01:51:56           36   \n",
      "\n",
      "                             aggregated_issue_titles  \n",
      "0  Issue: \"ConfigurationAction.doSetCardColor Per...  \n",
      "1  Issue: \"Heading is affecting further than what...  \n",
      "2  Issue: \"Improve logs per request\"\\nIssue: \"[PO...  \n",
      "3  Issue: \"JIRA Issues Macro returns \"\"Data canno...  \n",
      "4  Issue: \"UnsupportedOperationException: Asynchr...  \n"
     ]
    }
   ],
   "source": [
    "# Group issues by sprint and generate synthetic sprint goals\n",
    "\n",
    "# First, let's create a dataframe with unique sprints and their issues\n",
    "sprint_groups = df_explore.groupby('sprint_name')\n",
    "\n",
    "# Create a dataframe to store sprint information and their aggregated issues\n",
    "sprint_data = []\n",
    "\n",
    "for sprint_name, group in sprint_groups:\n",
    "    # Concatenate issue descriptions for this sprint\n",
    "    issue_titles = \"\\n\".join([f\"Issue: {row['issue_title']}\" for _, row in group.iterrows()])\n",
    "    \n",
    "    # Get other sprint information from the first row\n",
    "    first_row = group.iloc[0]\n",
    "    sprint_info = {\n",
    "        'sprint_name': sprint_name,\n",
    "        'project_name': first_row['project_name'],\n",
    "        'sprint_state': first_row['sprint_state'],\n",
    "        'sprint_start_date': first_row['sprint_start_date'],\n",
    "        'sprint_end_date': first_row['sprint_end_date'],\n",
    "        'issue_count': len(group),\n",
    "        'aggregated_issue_titles': issue_titles\n",
    "    }\n",
    "    \n",
    "    sprint_data.append(sprint_info)\n",
    "\n",
    "# Convert to DataFrame\n",
    "sprint_df = pd.DataFrame(sprint_data)\n",
    "\n",
    "# Display some statistics about the sprints\n",
    "print(f\"Total number of sprints: {len(sprint_df)}\")\n",
    "print(\"\\nSample of sprints:\")\n",
    "print(sprint_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating sprint goal for: 3.10-m3\n",
      "Generated goal: Enhance system stability and performance improvements across all major functionalities including improved Java version compatibility, resolved SVN operations issues, visibility of error messages, added support for more customizable access controls, addressed memory leaks during revision start-ups, fixed dead links in documentation, and enhanced security settings in FishEye.\n",
      "Issues for sprint '3.10-m3':\n",
      "- \"Update Java version bundled found in the installer to a version >= 1.8u51\"\n",
      "- \"SVN operations can hang in some cases when using svnkit with file:// protocol and long commit messages \"\n",
      "- \"Invisible error messages in admin pages\"\n",
      "- \"NPS warnings on instance startup\"\n",
      "- \"Add a link to include/exclude and patterns CAC page \"\n",
      "- \"OutOfMemoryError when Start Revision, Initial Import: \"\"No initial import\"\" and repository path are set\"\n",
      "- \"Dead Link for Allow 2-Legged OAuth in FishEye Crucible\"\n",
      "\n",
      "Generating sprint goal for: ESB Dolomite 2\n",
      "Generated goal: Develop and implement features to enhance Mule ESB's functionality through new components like Scatter-Gather for parallel multicasting, improve configuration management with updated settings for `MULE_HOME` and `MULE_BASE`, refine scripts related to versioning, streamline Maven project creation processes, and resolve FTP inbound endpoint issues upon encountering empty files.\n",
      "Issues for sprint 'ESB Dolomite 2':\n",
      "- \"Create Scatter-Gather component for parallel multicasting\"\n",
      "- \"Analyse the changes to have MULE_HOME and MULE_BASE\"\n",
      "- \"Remove installer specific behaviour from SwitchVersion script\"\n",
      "- \"Create mule domain + domain applications project creation using maven artifact.\"\n",
      "- \"FTP Inbound endpoint fails when reading empty file\"\n",
      "\n",
      "Generating sprint goal for: JVM Sprint 39\n",
      "Generated goal: Improve performance and stability across all Java components while addressing critical bugs and deprecated features, ensuring compatibility with newer MongoDB versions and enhancing logging practices.\n",
      "Issues for sprint 'JVM Sprint 39':\n",
      "- \"Remove dependency on javax.xml.bind.DatatypeConverter\"\n",
      "- \"Add Document.get(key, defaultValue)\"\n",
      "- \"fsyncunlock does not work on secondaries with 3.2.x\"\n",
      "- \"org.bson.json.JsonParseException: JSON reader was expecting a value but found '}'.\"\n",
      "- \"Connection failure from Android\"\n",
      "- \"Exception com.mongodb.MongoInternalException has error in its message\"\n",
      "- \"Investigate removing classmate dependency\"\n",
      "- \"NPE in PojoCodecProvider\"\n",
      "- \"Handle out-of-order keys in Extended JSON\"\n",
      "- \"Logging in org.bson should also use slf4j if possible\"\n",
      "- \"aggregation on view doesn't work \"\n",
      "- \"Memory leaks when using NettyStream and CommandListener\"\n",
      "- \"Spurious exception in maintenance task\"\n",
      "- \"Make driver-async an OSGI module\"\n",
      "- \"Deprecate modifiers in FindOptions and replace with properties\"\n",
      "- \"Support DBRef codec in async driver (MongoClients.DEFAULT_CODEC_REGISTRY)\"\n",
      "- \"$set fails when setting sub-document as a Map\"\n",
      "- \"Reduce memory requirements for Document and BsonDocument when the number of keys is small\"\n",
      "- \"Unclear API\"\n",
      "- \"Make RawBsonDocument#get return RawBsonDocument instances\"\n",
      "\n",
      "Generating sprint goal for: International 3.9 - Sprint 5\n",
      "Generated goal: Improve the TinyMCE editor's font size settings to ensure consistency across all Classic and child themes, addressing users who find the default font sizes too small.\n",
      "Issues for sprint 'International 3.9 - Sprint 5':\n",
      "- \"TinyMCE editor font sizes are too small in Classic theme (and other child themes)\"\n",
      "\n",
      "Generating sprint goal for: Uranium-235\n",
      "Generated goal: Improve user experience by resolving inconsistencies in status coloration across different applications, ensuring that temporary files for the Atlassian Companion App are stored correctly outside the Roaming profile on Windows, and addressing the system clock error issue when starting the Companion App.\n",
      "Issues for sprint 'Uranium-235':\n",
      "- \"Inconsistent status macro colours\"\n",
      "- \"Store temporary files for Atlassian Companion App outside of the Roaming profile on Windows\"\n",
      "- \"Companion App throws System clock error if it starts up before the computer has synced with the NTP server\"\n",
      "\n",
      "Generating sprint goal for: TSSW Sprint - Aug 5 - Aug 17\n",
      "Generated goal: Complete all necessary tasks related to software development, documentation updates, and system deployment for the upcoming project milestones.\n",
      "Issues for sprint 'TSSW Sprint - Aug 5 - Aug 17':\n",
      "- \"All Hands\"\n",
      "- \"Create the pub sub program\"\n",
      "- \"Moving Work and logistics\"\n",
      "- \"Learn the Jenkins Robotframework Pipeline\"\n",
      "- \"Write setup.py for ts_sal\"\n",
      "- \"PCW 2019\"\n",
      "- \"Image display + File monitor integration\"\n",
      "- \"LSST 2019 meeting\"\n",
      "- \"Test and release SAL V4\"\n",
      "- \"Modify run_atdome.py to use the standard CSC main method\"\n",
      "- \"PCW2019 - Rob\"\n",
      "- \"Epic to track folks time at the PCE\"\n",
      "- \"AT Whitelight returns\"\n",
      "- \"ATHexapod update for salobj 4\"\n",
      "- \"Check the M2 MATLAB Tool\"\n",
      "- \"Design salobj to Kafka feeder\"\n",
      "- \"Attend the Project Community Workshop\"\n",
      "- \"Review the Documents of Hexapod and Rotator in Phase 2\"\n",
      "- \"Deploy simulators on ncsa-integration-test-stand\"\n",
      "- \"Write python mitutoyo gauge wrapper\"\n",
      "- \"Split develop-env-conda into two images\"\n",
      "- \"Write ts_idl conda recipe and setup.py\"\n",
      "- \"Write Watcher model\"\n",
      "\n",
      "Generating sprint goal for: Mesosphere Sprint 2018-24\n",
      "Generated goal: Enhance container management capabilities including support for systemd and freezer cgroups, configurable GRPC call deadlines, improved logging for container preparation processes, and added garbage collection (GC) functionality for nested containers.\n",
      "Issues for sprint 'Mesosphere Sprint 2018-24':\n",
      "- \"Support systemd and freezer cgroup subsystems bind mount for container with rootfs.\"\n",
      "- \"Changing `CREATE_VOLUME` and `CREATE_BLOCK` to `CREATE_DISK`.\"\n",
      "- \"Make gRPC call deadline configurable.\"\n",
      "- \"Improve the container preparing logging in IOSwitchboard and volume/secret isolator.\"\n",
      "- \"Add GC capability to nested containers\"\n",
      "\n",
      "Generating sprint goal for: v2.0 (should do)\n",
      "Generated goal: Implement the feature allowing chaincode authors to securely initialize with their own private data.\n",
      "Issues for sprint 'v2.0 (should do)':\n",
      "- \"As a chaincode author, I want to set private data in chaincode Init()\"\n",
      "\n",
      "Generating sprint goal for: Sprint 4\n",
      "Generated goal: Improve integration testing framework and enhance documentation for Spring XD.\n",
      "Issues for sprint 'Sprint 4':\n",
      "- \"replace testsource with time and testsink with log\"\n",
      "- \"add spring-integration-groovy to container dependencies\"\n",
      "- \"add SpEL 'filter' processor\"\n",
      "- \"add SpEL 'transform' processor\"\n",
      "- \"Add install script for Redis\"\n",
      "- \"Update XD to Use SI 3.0.0.M2\"\n",
      "- \"Create final distribution zip across multiple projects\"\n",
      "- \"Documentation for starting Spring XD servers\"\n",
      "- \"Build script should not package 'spring-xd-dirt' scripts \"\n",
      "- \"Add LICENSE to be included in root directory of distribution\"\n",
      "- \"Add README to be included in root directory of distribution\"\n",
      "- \"Create XDAdmin server to start container launcher\"\n",
      "- \"Create XDContainer class to start stream server\"\n",
      "- \"Add gradle tasks that build and bundle the redis server\"\n",
      "- \"Sonar build is failing\"\n",
      "- \"Documentation on the module system and how to contribute new modules\"\n",
      "- \"Documentation for field value taps\"\n",
      "- \"Documentation for counter taps\"\n",
      "- \"Documentation for \"\"twittersearch | file\"\" processing\"\n",
      "- \"Documentation for \"\"gemfirecq | file\"\" processing\"\n",
      "- \"Documentation for \"\"http | gemfire\"\" processing\"\n",
      "- \"Documentation for \"\"tail | file\"\" processing\"\n",
      "- \"Documentation for \"\"http | hdfs\"\" processing\"\n",
      "- \"End user guide for data streams\"\n",
      "- \"Documentation for \"\"http | file\"\" processing\"\n",
      "- \"Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server\"\n",
      "- \"Add redis bundle to distribution zip file\"\n",
      "- \"Create XD module for tail file adapter\"\n",
      "- \"Provide a http source\"\n",
      "- \"Tuple should support storing nested tuples\"\n",
      "- \"Entity validation fails and throws a IndexOutOfBoundsException\"\n",
      "- \"Integrate CqlIdentifier\"\n",
      "- \"Add class AbstractCqlTemplateConfiguration\"\n",
      "- \"Enhance annotations to allow for force-quoting\"\n",
      "- \"Add support for missing DataTypes to DefaultCassandraRowValueProvider\"\n",
      "- \"Ensure all CqlOperations methods take QueryOptions where appropriate\"\n",
      "- \"Add overloaded methods to CqlOperations that use strongly typed Query objects\"\n",
      "- \"Ensure license text appears in all source files with proper dates.\"\n",
      "- \"xml:base URL embedded in yum metadata breaks proxy repositories\"\n",
      "- \"review File.mkdirs() usage, replace with Files.createDirectory(file.toPath()); to not hide IOExceptions\"\n",
      "- \"If \"\"application server settings (optional)\"\" is not checked than administration/server page can't be saved.\"\n",
      "- \"Remove pgp.mit.edu from list of uses SKS Keyservers\"\n",
      "- \"remove sonatype-indexer use of _magic_ annotations\"\n",
      "- \"Clean up use of injection in nexus-custom-metadata-plugin\"\n",
      "- \"Remove Managed and ExtensionPoint\"\n",
      "- \"System property http.proxyHost incompatible regular expressions, server wide\"\n",
      "- \"Yum proxy repository metadata is not refetched if request for it comes through a group repo\"\n",
      "- \"Old yum metadata is never cleaned up from yum proxy repository.\"\n",
      "- \"Automatic routing interferes with yum repo metadata\"\n",
      "- \"Repository is auto-blocked if \"\"allow file browsing\"\" is disabled on remote\"\n",
      "- \"Nexus OBR shadow makes Nexus deadlock prone, while reading/writing obr.xml\"\n",
      "- \"Cannot browse YUM repodata directory\"\n",
      "- \"Documentation for \"\"Running Bamboo service on Windows as the local user\"\" is missing\"\n",
      "- \"Include run as Service tutorial in Bamboo Linux Installation Documentation\"\n",
      "- \"Upgrade Bamboo Dashboard documentation\"\n",
      "- \"Write documentation for configuring the branch checking interval\"\n",
      "- \"Include documentation for configuring the gravatar server\"\n",
      "- \"Add documentation for the VCS Branching and VCS Tagging tasks\"\n",
      "- \"Wrapper references\"\n",
      "- \"Leave a note on the downloads page and the installation documents about the missing WAR package\"\n",
      "- \"Missing Documentation for the \"\"Audit Log\"\" feature\"\n",
      "- \"Update screen shots for Setup Wizard docs\"\n",
      "- \"Document applinks and entity links in Bamboo more fully\"\n",
      "- \"Improve the docs for running Bamboo over https\"\n",
      "- \"Add warnings in UI about install/deploy phases\"\n",
      "- \"Insert Clover goals between original ones\"\n",
      "- \"BAM-13208 Automatic integration in multi-module builds\"\n",
      "- \"Rename com.cenqua to com.atlassian\"\n",
      "- \"Several tests fail with Cannot cast object ... to class 'com_cenqua_clover.CoverageRecorder'\"\n",
      "- \"change small class histogram into container\"\n",
      "- \"change project/package statistics to the boxed component\"\n",
      "- \"as a developer I'd like to generate reports with Java8 sources\"\n",
      "- \"as a developer I'd like to instrument Java8 new language features\"\n",
      "- \"Remove unused remote_address_binary and remote_address_mask columns\"\n",
      "- \"Add an extra information in the Issue Security documentation\"\n",
      "- \"Time Tracking Reports Documentation Outdated\"\n",
      "- \"Update JIRA REST documentation about removing a user from a project role\"\n",
      "- \"Update Creating Issue and Comments documentation\"\n",
      "- \"Application Documentation Error\"\n",
      "- \"Update Pie Chart Documentation for JIRA Server + Cloud\"\n",
      "- \"Upgrading JIRA Manually Instructions update suggestions\"\n",
      "- \"Releases notes for 6.1.2 should warn of ORA-01408 error on first start\"\n",
      "- \"Update JIRA REST documentation about setting users/groups to a project role\"\n",
      "- \"Update Configuring JIRA Options documentation regarding Gravatars\"\n",
      "- \"Link broken on Google Apps Integration FAQ\"\n",
      "- \"Update the recommendation for interim upgrade to any version below 4.3 go first to version 4.4.5\"\n",
      "- \"Modified the attachments query\"\n",
      "- \"Update instructions for installing on MAC OS X\"\n",
      "- \"Column titles in board configuration overflow disasterously\"\n",
      "- \"Bump maven-jira-plugin version to 3.9.1\"\n",
      "- \"Get GreenHopper 5.1 compatible\"\n",
      "- \" MVR: Agile issue web panel to display Scrum information of an issue\"\n",
      "- \"GreenHopper doesn't respect JIRA's avatar settings\"\n",
      "- \"Cycle time getting some very big values in certain conditions\"\n",
      "- \"Upgrade task to unify Board/Sprint data into AO instead of using PropertySets\"\n",
      "- \"Sprint marker jumps to bottom of the backlog if you delete an issue in a sprint\"\n",
      "- \"As a user I would like to go to GH as my default JIRa home page\"\n",
      "- \"MV?: Implement the skinny detail view\"\n",
      "- \"Cycle time not shown on hover when only one status selected in the control graph\"\n",
      "- \"As a control chart user, I want to see actual values of the moving average on hover \"\n",
      "- \"MVR: Prompt the user to resolve the parent when the subtasks are all done \"\n",
      "- \"MVR: Implement visualisation of swimlanes as parents \"\n",
      "- \"MVR: Issue operation to jump to a rapid board from an Issue\"\n",
      "- \"Control graphs should show hours if less than 1d\"\n",
      "- \"Column titles in board configuration overflow disasterously\"\n",
      "- \"Bump maven-jira-plugin version to 3.9.1\"\n",
      "- \"Get GreenHopper 5.1 compatible\"\n",
      "- \" MVR: Agile issue web panel to display Scrum information of an issue\"\n",
      "- \"Greenhopper license with expired maintenance period does not work in JIRA 5.0.1 and Greenhopper 5.9.1\"\n",
      "- \"GreenHopper doesn't respect JIRA's avatar settings\"\n",
      "- \"Cycle time getting some very big values in certain conditions\"\n",
      "- \"Component dropdown in List View on Planning Board shrinks to 1 character wide in IE8/Win7 when a lot of fields are added\"\n",
      "- \"Upgrade task to unify Board/Sprint data into AO instead of using PropertySets\"\n",
      "- \"Sprint marker jumps to bottom of the backlog if you delete an issue in a sprint\"\n",
      "- \"As a user I would like to go to GH as my default JIRa home page\"\n",
      "- \"MV?: Implement the skinny detail view\"\n",
      "- \"MV?: When all of the subtasks of a story are complete but the parent is not show an affordance that can be clicked by the user to advance the parent (and try to resolve the issue)\"\n",
      "- \"Cycle time not shown on hover when only one status selected in the control graph\"\n",
      "- \"As a control chart user, I want to see actual values of the moving average on hover \"\n",
      "- \"MVR: Prompt the user to resolve the parent when the subtasks are all done \"\n",
      "- \"Performance: Improve load time of the filter list when creating a new board\"\n",
      "- \"MVR: Implement visualisation of swimlanes as parents \"\n",
      "- \"MVR: Issue operation to jump to a rapid board from an Issue\"\n",
      "- \"Control graphs should show hours if less than 1d\"\n",
      "- \"chaincode url decode should never return empty urllocation with no error\"\n",
      "- \"OSX local run chaincode -> Killed: 9\"\n",
      "- \"Implement serialize method of SigningIdentity\"\n",
      "- \"Implement serialize method of Identity\"\n",
      "- \"Support golang 1.8\"\n",
      "- \"send_transaction\"\n",
      "- \"create_transaction\"\n",
      "- \"create_transaction_proposal\"\n",
      "- \"send_transaction_proposal\"\n",
      "- \"MVP design and implementation - python SDK\"\n",
      "- \"Fix unnessary errorf, fatalf statement in configtx package\"\n",
      "- \"Unstable re-compiling after `make peer` fails \"\n",
      "- \"2.12.0-rc0 logs JMX InstanceAlreadyExistsException at WARNING level\"\n",
      "- \"Support parallelCollectionScan command\"\n",
      "- \"DBRefBase should implement Serializable\"\n",
      "- \"Remove autoConnectRetry and maxAutoConnectRetryTime options\"\n",
      "- \"Remove support for w = -1\"\n",
      "- \"update description of fsync write concern flag\"\n",
      "- \"Allow acceptable latency difference to be configured via API\"\n",
      "- \"Deprecate com.mongodb.WriteResult#getLastError methods\"\n",
      "- \"Allow configuration of heartbeat background threads to be set via API\"\n",
      "- \"Improve scaffolder logging when yaml file is not valid\"\n",
      "- \"Scaffolder is not setting complete path for the resource\"\n",
      "- \"When generating a mule config file from scratch from yaml, the config-ref in the router is incorrect\"\n",
      "- \"Scaffolder cannot find included files in yaml\"\n",
      "- \"Generated flows don't have the correct indentation\"\n",
      "- \"Scaffolder is duplicating flows\"\n",
      "- \"scaffolder is not generating flows properly\"\n",
      "- \"yaml file generated with Maven archetype should have global tag set to tag:raml.org,0.1:\"\n",
      "- \"Update scaffolder mule config with latest changes\"\n",
      "- \"Create script to populate apikit dependences, archetype and maven plugin\"\n",
      "- \"Raml file created should have .yaml extension\"\n",
      "- \"Update archetype mule config with latest changes\"\n",
      "- \"Remove EE repositories from pom file generated with Maven archetype\"\n",
      "- \"mvn:apikit create - config file created should be included in mule-config.xml file\"\n",
      "- \"Maven archetype does not add port to http endpoint\"\n",
      "- \"Mule 3.2.1 HTTPS outbound endpoint leaking file descriptors\"\n",
      "- \"Bookstore example fails to show stats page\"\n",
      "- \"Inserting <collection-splitter /><collection-aggregator /> into a flow produces unexpected results\"\n",
      "- \"Add an extra information in the Issue Security documentation\"\n",
      "- \"Time Tracking Reports Documentation Outdated\"\n",
      "- \"Update JIRA REST documentation about removing a user from a project role\"\n",
      "- \"Update Creating Issue and Comments documentation\"\n",
      "- \"Application Documentation Error\"\n",
      "- \"Update Pie Chart Documentation for JIRA Server + Cloud\"\n",
      "- \"Upgrading JIRA Manually Instructions update suggestions\"\n",
      "- \"Releases notes for 6.1.2 should warn of ORA-01408 error on first start\"\n",
      "- \"Update JIRA REST documentation about setting users/groups to a project role\"\n",
      "- \"Update Configuring JIRA Options documentation regarding Gravatars\"\n",
      "- \"Link broken on Google Apps Integration FAQ\"\n",
      "- \"JQL documentation for searching Labels field\"\n",
      "- \"Update the recommendation for interim upgrade to any version below 4.3 go first to version 4.4.5\"\n",
      "- \"Modified the attachments query\"\n",
      "- \"Update instructions for installing on MAC OS X\"\n",
      "\n",
      "Generating sprint goal for: DRP S20-2 (Jan)\n",
      "Generated goal: Create comprehensive updates to the observatory science tools (OST) repository, including presentations, model additions, validation fixes, and improvements to existing features such as multi-frame processing, quality assurance, and user interface enhancements.\n",
      "Issues for sprint 'DRP S20-2 (Jan)':\n",
      "- \"Create presentation for SST on deblending in the stack\"\n",
      "- \"Add two-component models to MultiProFitTask\"\n",
      "- \"validate_drp crashes when trying to apply external skyWcs\"\n",
      "- \"Store MultiComponentSource components in catalog\"\n",
      "- \"Add matchedVisitMetric configs to obs_subaru\"\n",
      "- \"Use correct weight maps in scarlet\"\n",
      "- \"Fit DC2 with MultiProFit\"\n",
      "- \"Fix \"\"unordered\"\" map documentation in DetectorCollection getters\"\n",
      "- \"Augment ObjectTable to be useable for QA\"\n",
      "- \"Update python types for matchVisits and objectTable\"\n",
      "- \"HSC-Y failed on w_2020_02\"\n",
      "- \"Add sky objects to the single frame processing step\"\n",
      "- \"Delete commented code in tests/test_matchBackgrounds.py\"\n",
      "- \"Test fgcmcal on NB0387 HSC data\"\n",
      "- \"Fix association of flag columns to forced_src catalogs\"\n",
      "- \"Understand problem with modelling bright stars' wings\"\n",
      "- \"Add ability for fgcmcal to do calibrations on local background-corrected fluxes\"\n",
      "- \"Investigate galaxy bias introduced with scarlet 1.0\"\n",
      "- \"Remove SubaruMakeCoaddTempExpTask after S19A AND problem  fixed upstream\"\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic sprint goals for a subset of sprints (to avoid long runtimes)\n",
    "# You can adjust the sample size based on your computational resources\n",
    "\n",
    "# Take a sample of sprints to generate goals for (adjust as needed)\n",
    "# sample_size = 10  # Start with a small number to test\n",
    "# sprints_for_goals = sprint_df.sample(sample_size, random_state=42) if len(sprint_df) > sample_size else sprint_df\n",
    "\n",
    "# Generate sprint goals for the sampled sprints\n",
    "for idx, row in sprints_for_goals.iterrows():\n",
    "    sprint_name = row['sprint_name']\n",
    "    issue_titles = row['aggregated_issue_titles']\n",
    "    \n",
    "    print(f\"\\nGenerating sprint goal for: {sprint_name}\")\n",
    "    goal = generate_sprint_goal(issue_titles)\n",
    "    \n",
    "    # Update the dataframe with the generated goal\n",
    "    sprint_df.loc[idx, 'synthetic_sprint_goal'] = goal\n",
    "    print(f\"Generated goal: {goal}\")\n",
    "    # Print the issues for the current sprint\n",
    "    sprint_issues = df_explore[df_explore['sprint_name'] == sprint_name]\n",
    "    print(f\"Issues for sprint '{sprint_name}':\")\n",
    "    for _, issue_row in sprint_issues.iterrows():\n",
    "        print(f\"- {issue_row['issue_title']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 10\n",
      "\n",
      "Sample of restructured training data:\n",
      "                    sprint_name  \\\n",
      "0                       3.10-m3   \n",
      "1               DRP S20-2 (Jan)   \n",
      "2                ESB Dolomite 2   \n",
      "3  International 3.9 - Sprint 5   \n",
      "4                 JVM Sprint 39   \n",
      "\n",
      "                                         sprint_goal  \\\n",
      "0  Enhance system stability and performance impro...   \n",
      "1  Create comprehensive updates to the observator...   \n",
      "2  Develop and implement features to enhance Mule...   \n",
      "3  Improve the TinyMCE editor's font size setting...   \n",
      "4  Improve performance and stability across all J...   \n",
      "\n",
      "                                    formatted_issues  \n",
      "0  - \"Update Java version bundled found in the in...  \n",
      "1  - \"Create presentation for SST on deblending i...  \n",
      "2  - \"Create Scatter-Gather component for paralle...  \n",
      "3  - \"TinyMCE editor font sizes are too small in ...  \n",
      "4  - \"Remove dependency on javax.xml.bind.Datatyp...  \n",
      "\n",
      "Training data saved to ../data/sprint_goals_training_data.jsonl\n",
      "\n",
      "Example training pairs:\n",
      "\n",
      "--- Example 1 ---\n",
      "Prompt (Sprint Goal): Enhance system stability and performance improvements across all major functionalities including improved Java version compatibility, resolved SVN operations issues, visibility of error messages, added support for more customizable access controls, addressed memory leaks during revision start-ups, fixed dead links in documentation, and enhanced security settings in FishEye.\n",
      "Reference (Issues):\n",
      "- \"Update Java version bundled found in the installer to a version >= 1.8u51\"\n",
      "- \"SVN operations can hang in some cases when using svnkit with file:// protocol and long commit messages \"\n",
      "- \"Invisible error messages in admin pages\"\n",
      "- \"NPS warnings on instance startup\"\n",
      "- \"Add a link to include/exclude and patterns CAC page \"\n",
      "- \"OutOfMemoryError when Start Revision, Initial Import: \"\"No initial import\"\" and repository path are set\"\n",
      "- \"Dead Link for Allow 2-Legged OAuth in FishEye Crucible\"\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 2 ---\n",
      "Prompt (Sprint Goal): Create comprehensive updates to the observatory science tools (OST) repository, including presentations, model additions, validation fixes, and improvements to existing features such as multi-frame processing, quality assurance, and user interface enhancements.\n",
      "Reference (Issues):\n",
      "- \"Create presentation for SST on deblending in the stack\"\n",
      "- \"Add two-component models to MultiProFitTask\"\n",
      "- \"validate_drp crashes when trying to apply external skyWcs\"\n",
      "- \"Store MultiComponentSource components in catalog\"\n",
      "- \"Add matchedVisitMetric configs to obs_subaru\"\n",
      "- \"Use correct weight maps in scarlet\"\n",
      "- \"Fit DC2 with MultiProFit\"\n",
      "- \"Fix \"\"unordered\"\" map documentation in DetectorCollection getters\"\n",
      "- \"Augment ObjectTable to be useable for QA\"\n",
      "- \"Update python types for matchVisits and objectTable\"\n",
      "- \"HSC-Y failed on w_2020_02\"\n",
      "- \"Add sky objects to the single frame processing step\"\n",
      "- \"Delete commented code in tests/test_matchBackgrounds.py\"\n",
      "- \"Test fgcmcal on NB0387 HSC data\"\n",
      "- \"Fix association of flag columns to forced_src catalogs\"\n",
      "- \"Understand problem with modelling bright stars' wings\"\n",
      "- \"Add ability for fgcmcal to do calibrations on local background-corrected fluxes\"\n",
      "- \"Investigate galaxy bias introduced with scarlet 1.0\"\n",
      "- \"Remove SubaruMakeCoaddTempExpTask after S19A AND problem  fixed upstream\"\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 3 ---\n",
      "Prompt (Sprint Goal): Develop and implement features to enhance Mule ESB's functionality through new components like Scatter-Gather for parallel multicasting, improve configuration management with updated settings for `MULE_HOME` and `MULE_BASE`, refine scripts related to versioning, streamline Maven project creation processes, and resolve FTP inbound endpoint issues upon encountering empty files.\n",
      "Reference (Issues):\n",
      "- \"Create Scatter-Gather component for parallel multicasting\"\n",
      "- \"Analyse the changes to have MULE_HOME and MULE_BASE\"\n",
      "- \"Remove installer specific behaviour from SwitchVersion script\"\n",
      "- \"Create mule domain + domain applications project creation using maven artifact.\"\n",
      "- \"FTP Inbound endpoint fails when reading empty file\"\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 4 ---\n",
      "Prompt (Sprint Goal): Improve the TinyMCE editor's font size settings to ensure consistency across all Classic and child themes, addressing users who find the default font sizes too small.\n",
      "Reference (Issues):\n",
      "- \"TinyMCE editor font sizes are too small in Classic theme (and other child themes)\"\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Example 5 ---\n",
      "Prompt (Sprint Goal): Improve performance and stability across all Java components while addressing critical bugs and deprecated features, ensuring compatibility with newer MongoDB versions and enhancing logging practices.\n",
      "Reference (Issues):\n",
      "- \"Remove dependency on javax.xml.bind.DatatypeConverter\"\n",
      "- \"Add Document.get(key, defaultValue)\"\n",
      "- \"fsyncunlock does not work on secondaries with 3.2.x\"\n",
      "- \"org.bson.json.JsonParseException: JSON reader was expecting a value but found '}'.\"\n",
      "- \"Connection failure from Android\"\n",
      "- \"Exception com.mongodb.MongoInternalException has error in its message\"\n",
      "- \"Investigate removing classmate dependency\"\n",
      "- \"NPE in PojoCodecProvider\"\n",
      "- \"Handle out-of-order keys in Extended JSON\"\n",
      "- \"Logging in org.bson should also use slf4j if possible\"\n",
      "- \"aggregation on view doesn't work \"\n",
      "- \"Memory leaks when using NettyStream and CommandListener\"\n",
      "- \"Spurious exception in maintenance task\"\n",
      "- \"Make driver-async an OSGI module\"\n",
      "- \"Deprecate modifiers in FindOptions and replace with properties\"\n",
      "- \"Support DBRef codec in async driver (MongoClients.DEFAULT_CODEC_REGISTRY)\"\n",
      "- \"$set fails when setting sub-document as a Map\"\n",
      "- \"Reduce memory requirements for Document and BsonDocument when the number of keys is small\"\n",
      "- \"Unclear API\"\n",
      "- \"Make RawBsonDocument#get return RawBsonDocument instances\"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a sprint goal to issues mapping for the training dataset\n",
    "\n",
    "# Process only sprints that have synthetic goals\n",
    "sprint_training_data = []\n",
    "\n",
    "for idx, sprint_row in sprint_df[sprint_df['synthetic_sprint_goal'].notna()].iterrows():\n",
    "    sprint_name = sprint_row['sprint_name']\n",
    "    sprint_goal = sprint_row['synthetic_sprint_goal']\n",
    "    \n",
    "    # Get all issues for this sprint\n",
    "    sprint_issues = df_explore[df_explore['sprint_name'] == sprint_name]\n",
    "    \n",
    "    # Format the issues as a single string with bullet points\n",
    "    formatted_issues = \"\\n\".join([f\"- {row['issue_title']}\" for _, row in sprint_issues.iterrows()])\n",
    "    \n",
    "    # Create the training example with sprint goal as prompt and issues as reference\n",
    "    example = {\n",
    "        'sprint_name': sprint_name,\n",
    "        'sprint_goal': sprint_goal,  # synthetic goal as x\n",
    "        'formatted_issues': formatted_issues,  # actual issues as y\n",
    "        'num_issues': len(sprint_issues)\n",
    "    }\n",
    "    \n",
    "    sprint_training_data.append(example)\n",
    "\n",
    "# Convert to DataFrame\n",
    "sprint_training_df = pd.DataFrame(sprint_training_data)\n",
    "\n",
    "# Preview the restructured training data\n",
    "print(f\"Total training examples: {len(sprint_training_df)}\")\n",
    "print(\"\\nSample of restructured training data:\")\n",
    "print(sprint_training_df[['sprint_name', 'sprint_goal', 'formatted_issues']].head())\n",
    "\n",
    "# Save the training data as JSONL for use with train.py\n",
    "sprint_training_path = '../data/sprint_goals_training_data.jsonl'\n",
    "sprint_training_df.to_json(sprint_training_path, orient='records', lines=True)\n",
    "print(f\"\\nTraining data saved to {sprint_training_path}\")\n",
    "\n",
    "# Print a few examples to verify the format\n",
    "print(\"\\nExample training pairs:\")\n",
    "for i, (_, row) in enumerate(sprint_training_df.head().iterrows()):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Prompt (Sprint Goal): {row['sprint_goal']}\")\n",
    "    print(f\"Reference (Issues):\\n{row['formatted_issues']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sprint Goal: Enhance system stability and performance improvements across all major functionalities including improved Java version compatibility, resolved SVN operations issues, visibility of error messages, added support for more customizable access controls, addressed memory leaks during revision start-ups, fixed dead links in documentation, and enhanced security settings in FishEye.\n",
      "Issue Titles:\n",
      "- \"Update Java version bundled found in the installer to a version >= 1.8u51\"\n",
      "- \"SVN operations can hang in some cases when using svnkit with file:// protocol and long commit messages \"\n",
      "- \"Invisible error messages in admin pages\"\n",
      "- \"NPS warnings on instance startup\"\n",
      "- \"Add a link to include/exclude and patterns CAC page \"\n",
      "- \"OutOfMemoryError when Start Revision, Initial Import: \"\"No initial import\"\" and repository path are set\"\n",
      "- \"Dead Link for Allow 2-Legged OAuth in FishEye Crucible\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Create comprehensive updates to the observatory science tools (OST) repository, including presentations, model additions, validation fixes, and improvements to existing features such as multi-frame processing, quality assurance, and user interface enhancements.\n",
      "Issue Titles:\n",
      "- \"Create presentation for SST on deblending in the stack\"\n",
      "- \"Add two-component models to MultiProFitTask\"\n",
      "- \"validate_drp crashes when trying to apply external skyWcs\"\n",
      "- \"Store MultiComponentSource components in catalog\"\n",
      "- \"Add matchedVisitMetric configs to obs_subaru\"\n",
      "- \"Use correct weight maps in scarlet\"\n",
      "- \"Fit DC2 with MultiProFit\"\n",
      "- \"Fix \"\"unordered\"\" map documentation in DetectorCollection getters\"\n",
      "- \"Augment ObjectTable to be useable for QA\"\n",
      "- \"Update python types for matchVisits and objectTable\"\n",
      "- \"HSC-Y failed on w_2020_02\"\n",
      "- \"Add sky objects to the single frame processing step\"\n",
      "- \"Delete commented code in tests/test_matchBackgrounds.py\"\n",
      "- \"Test fgcmcal on NB0387 HSC data\"\n",
      "- \"Fix association of flag columns to forced_src catalogs\"\n",
      "- \"Understand problem with modelling bright stars' wings\"\n",
      "- \"Add ability for fgcmcal to do calibrations on local background-corrected fluxes\"\n",
      "- \"Investigate galaxy bias introduced with scarlet 1.0\"\n",
      "- \"Remove SubaruMakeCoaddTempExpTask after S19A AND problem  fixed upstream\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Develop and implement features to enhance Mule ESB's functionality through new components like Scatter-Gather for parallel multicasting, improve configuration management with updated settings for `MULE_HOME` and `MULE_BASE`, refine scripts related to versioning, streamline Maven project creation processes, and resolve FTP inbound endpoint issues upon encountering empty files.\n",
      "Issue Titles:\n",
      "- \"Create Scatter-Gather component for parallel multicasting\"\n",
      "- \"Analyse the changes to have MULE_HOME and MULE_BASE\"\n",
      "- \"Remove installer specific behaviour from SwitchVersion script\"\n",
      "- \"Create mule domain + domain applications project creation using maven artifact.\"\n",
      "- \"FTP Inbound endpoint fails when reading empty file\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Improve the TinyMCE editor's font size settings to ensure consistency across all Classic and child themes, addressing users who find the default font sizes too small.\n",
      "Issue Titles:\n",
      "- \"TinyMCE editor font sizes are too small in Classic theme (and other child themes)\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Improve performance and stability across all Java components while addressing critical bugs and deprecated features, ensuring compatibility with newer MongoDB versions and enhancing logging practices.\n",
      "Issue Titles:\n",
      "- \"Remove dependency on javax.xml.bind.DatatypeConverter\"\n",
      "- \"Add Document.get(key, defaultValue)\"\n",
      "- \"fsyncunlock does not work on secondaries with 3.2.x\"\n",
      "- \"org.bson.json.JsonParseException: JSON reader was expecting a value but found '}'.\"\n",
      "- \"Connection failure from Android\"\n",
      "- \"Exception com.mongodb.MongoInternalException has error in its message\"\n",
      "- \"Investigate removing classmate dependency\"\n",
      "- \"NPE in PojoCodecProvider\"\n",
      "- \"Handle out-of-order keys in Extended JSON\"\n",
      "- \"Logging in org.bson should also use slf4j if possible\"\n",
      "- \"aggregation on view doesn't work \"\n",
      "- \"Memory leaks when using NettyStream and CommandListener\"\n",
      "- \"Spurious exception in maintenance task\"\n",
      "- \"Make driver-async an OSGI module\"\n",
      "- \"Deprecate modifiers in FindOptions and replace with properties\"\n",
      "- \"Support DBRef codec in async driver (MongoClients.DEFAULT_CODEC_REGISTRY)\"\n",
      "- \"$set fails when setting sub-document as a Map\"\n",
      "- \"Reduce memory requirements for Document and BsonDocument when the number of keys is small\"\n",
      "- \"Unclear API\"\n",
      "- \"Make RawBsonDocument#get return RawBsonDocument instances\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Enhance container management capabilities including support for systemd and freezer cgroups, configurable GRPC call deadlines, improved logging for container preparation processes, and added garbage collection (GC) functionality for nested containers.\n",
      "Issue Titles:\n",
      "- \"Support systemd and freezer cgroup subsystems bind mount for container with rootfs.\"\n",
      "- \"Changing `CREATE_VOLUME` and `CREATE_BLOCK` to `CREATE_DISK`.\"\n",
      "- \"Make gRPC call deadline configurable.\"\n",
      "- \"Improve the container preparing logging in IOSwitchboard and volume/secret isolator.\"\n",
      "- \"Add GC capability to nested containers\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Improve integration testing framework and enhance documentation for Spring XD.\n",
      "Issue Titles:\n",
      "- \"replace testsource with time and testsink with log\"\n",
      "- \"add spring-integration-groovy to container dependencies\"\n",
      "- \"add SpEL 'filter' processor\"\n",
      "- \"add SpEL 'transform' processor\"\n",
      "- \"Add install script for Redis\"\n",
      "- \"Update XD to Use SI 3.0.0.M2\"\n",
      "- \"Create final distribution zip across multiple projects\"\n",
      "- \"Documentation for starting Spring XD servers\"\n",
      "- \"Build script should not package 'spring-xd-dirt' scripts \"\n",
      "- \"Add LICENSE to be included in root directory of distribution\"\n",
      "- \"Add README to be included in root directory of distribution\"\n",
      "- \"Create XDAdmin server to start container launcher\"\n",
      "- \"Create XDContainer class to start stream server\"\n",
      "- \"Add gradle tasks that build and bundle the redis server\"\n",
      "- \"Sonar build is failing\"\n",
      "- \"Documentation on the module system and how to contribute new modules\"\n",
      "- \"Documentation for field value taps\"\n",
      "- \"Documentation for counter taps\"\n",
      "- \"Documentation for \"\"twittersearch | file\"\" processing\"\n",
      "- \"Documentation for \"\"gemfirecq | file\"\" processing\"\n",
      "- \"Documentation for \"\"http | gemfire\"\" processing\"\n",
      "- \"Documentation for \"\"tail | file\"\" processing\"\n",
      "- \"Documentation for \"\"http | hdfs\"\" processing\"\n",
      "- \"End user guide for data streams\"\n",
      "- \"Documentation for \"\"http | file\"\" processing\"\n",
      "- \"Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server\"\n",
      "- \"Add redis bundle to distribution zip file\"\n",
      "- \"Create XD module for tail file adapter\"\n",
      "- \"Provide a http source\"\n",
      "- \"Tuple should support storing nested tuples\"\n",
      "- \"Entity validation fails and throws a IndexOutOfBoundsException\"\n",
      "- \"Integrate CqlIdentifier\"\n",
      "- \"Add class AbstractCqlTemplateConfiguration\"\n",
      "- \"Enhance annotations to allow for force-quoting\"\n",
      "- \"Add support for missing DataTypes to DefaultCassandraRowValueProvider\"\n",
      "- \"Ensure all CqlOperations methods take QueryOptions where appropriate\"\n",
      "- \"Add overloaded methods to CqlOperations that use strongly typed Query objects\"\n",
      "- \"Ensure license text appears in all source files with proper dates.\"\n",
      "- \"xml:base URL embedded in yum metadata breaks proxy repositories\"\n",
      "- \"review File.mkdirs() usage, replace with Files.createDirectory(file.toPath()); to not hide IOExceptions\"\n",
      "- \"If \"\"application server settings (optional)\"\" is not checked than administration/server page can't be saved.\"\n",
      "- \"Remove pgp.mit.edu from list of uses SKS Keyservers\"\n",
      "- \"remove sonatype-indexer use of _magic_ annotations\"\n",
      "- \"Clean up use of injection in nexus-custom-metadata-plugin\"\n",
      "- \"Remove Managed and ExtensionPoint\"\n",
      "- \"System property http.proxyHost incompatible regular expressions, server wide\"\n",
      "- \"Yum proxy repository metadata is not refetched if request for it comes through a group repo\"\n",
      "- \"Old yum metadata is never cleaned up from yum proxy repository.\"\n",
      "- \"Automatic routing interferes with yum repo metadata\"\n",
      "- \"Repository is auto-blocked if \"\"allow file browsing\"\" is disabled on remote\"\n",
      "- \"Nexus OBR shadow makes Nexus deadlock prone, while reading/writing obr.xml\"\n",
      "- \"Cannot browse YUM repodata directory\"\n",
      "- \"Documentation for \"\"Running Bamboo service on Windows as the local user\"\" is missing\"\n",
      "- \"Include run as Service tutorial in Bamboo Linux Installation Documentation\"\n",
      "- \"Upgrade Bamboo Dashboard documentation\"\n",
      "- \"Write documentation for configuring the branch checking interval\"\n",
      "- \"Include documentation for configuring the gravatar server\"\n",
      "- \"Add documentation for the VCS Branching and VCS Tagging tasks\"\n",
      "- \"Wrapper references\"\n",
      "- \"Leave a note on the downloads page and the installation documents about the missing WAR package\"\n",
      "- \"Missing Documentation for the \"\"Audit Log\"\" feature\"\n",
      "- \"Update screen shots for Setup Wizard docs\"\n",
      "- \"Document applinks and entity links in Bamboo more fully\"\n",
      "- \"Improve the docs for running Bamboo over https\"\n",
      "- \"Add warnings in UI about install/deploy phases\"\n",
      "- \"Insert Clover goals between original ones\"\n",
      "- \"BAM-13208 Automatic integration in multi-module builds\"\n",
      "- \"Rename com.cenqua to com.atlassian\"\n",
      "- \"Several tests fail with Cannot cast object ... to class 'com_cenqua_clover.CoverageRecorder'\"\n",
      "- \"change small class histogram into container\"\n",
      "- \"change project/package statistics to the boxed component\"\n",
      "- \"as a developer I'd like to generate reports with Java8 sources\"\n",
      "- \"as a developer I'd like to instrument Java8 new language features\"\n",
      "- \"Remove unused remote_address_binary and remote_address_mask columns\"\n",
      "- \"Add an extra information in the Issue Security documentation\"\n",
      "- \"Time Tracking Reports Documentation Outdated\"\n",
      "- \"Update JIRA REST documentation about removing a user from a project role\"\n",
      "- \"Update Creating Issue and Comments documentation\"\n",
      "- \"Application Documentation Error\"\n",
      "- \"Update Pie Chart Documentation for JIRA Server + Cloud\"\n",
      "- \"Upgrading JIRA Manually Instructions update suggestions\"\n",
      "- \"Releases notes for 6.1.2 should warn of ORA-01408 error on first start\"\n",
      "- \"Update JIRA REST documentation about setting users/groups to a project role\"\n",
      "- \"Update Configuring JIRA Options documentation regarding Gravatars\"\n",
      "- \"Link broken on Google Apps Integration FAQ\"\n",
      "- \"Update the recommendation for interim upgrade to any version below 4.3 go first to version 4.4.5\"\n",
      "- \"Modified the attachments query\"\n",
      "- \"Update instructions for installing on MAC OS X\"\n",
      "- \"Column titles in board configuration overflow disasterously\"\n",
      "- \"Bump maven-jira-plugin version to 3.9.1\"\n",
      "- \"Get GreenHopper 5.1 compatible\"\n",
      "- \" MVR: Agile issue web panel to display Scrum information of an issue\"\n",
      "- \"GreenHopper doesn't respect JIRA's avatar settings\"\n",
      "- \"Cycle time getting some very big values in certain conditions\"\n",
      "- \"Upgrade task to unify Board/Sprint data into AO instead of using PropertySets\"\n",
      "- \"Sprint marker jumps to bottom of the backlog if you delete an issue in a sprint\"\n",
      "- \"As a user I would like to go to GH as my default JIRa home page\"\n",
      "- \"MV?: Implement the skinny detail view\"\n",
      "- \"Cycle time not shown on hover when only one status selected in the control graph\"\n",
      "- \"As a control chart user, I want to see actual values of the moving average on hover \"\n",
      "- \"MVR: Prompt the user to resolve the parent when the subtasks are all done \"\n",
      "- \"MVR: Implement visualisation of swimlanes as parents \"\n",
      "- \"MVR: Issue operation to jump to a rapid board from an Issue\"\n",
      "- \"Control graphs should show hours if less than 1d\"\n",
      "- \"Column titles in board configuration overflow disasterously\"\n",
      "- \"Bump maven-jira-plugin version to 3.9.1\"\n",
      "- \"Get GreenHopper 5.1 compatible\"\n",
      "- \" MVR: Agile issue web panel to display Scrum information of an issue\"\n",
      "- \"Greenhopper license with expired maintenance period does not work in JIRA 5.0.1 and Greenhopper 5.9.1\"\n",
      "- \"GreenHopper doesn't respect JIRA's avatar settings\"\n",
      "- \"Cycle time getting some very big values in certain conditions\"\n",
      "- \"Component dropdown in List View on Planning Board shrinks to 1 character wide in IE8/Win7 when a lot of fields are added\"\n",
      "- \"Upgrade task to unify Board/Sprint data into AO instead of using PropertySets\"\n",
      "- \"Sprint marker jumps to bottom of the backlog if you delete an issue in a sprint\"\n",
      "- \"As a user I would like to go to GH as my default JIRa home page\"\n",
      "- \"MV?: Implement the skinny detail view\"\n",
      "- \"MV?: When all of the subtasks of a story are complete but the parent is not show an affordance that can be clicked by the user to advance the parent (and try to resolve the issue)\"\n",
      "- \"Cycle time not shown on hover when only one status selected in the control graph\"\n",
      "- \"As a control chart user, I want to see actual values of the moving average on hover \"\n",
      "- \"MVR: Prompt the user to resolve the parent when the subtasks are all done \"\n",
      "- \"Performance: Improve load time of the filter list when creating a new board\"\n",
      "- \"MVR: Implement visualisation of swimlanes as parents \"\n",
      "- \"MVR: Issue operation to jump to a rapid board from an Issue\"\n",
      "- \"Control graphs should show hours if less than 1d\"\n",
      "- \"chaincode url decode should never return empty urllocation with no error\"\n",
      "- \"OSX local run chaincode -> Killed: 9\"\n",
      "- \"Implement serialize method of SigningIdentity\"\n",
      "- \"Implement serialize method of Identity\"\n",
      "- \"Support golang 1.8\"\n",
      "- \"send_transaction\"\n",
      "- \"create_transaction\"\n",
      "- \"create_transaction_proposal\"\n",
      "- \"send_transaction_proposal\"\n",
      "- \"MVP design and implementation - python SDK\"\n",
      "- \"Fix unnessary errorf, fatalf statement in configtx package\"\n",
      "- \"Unstable re-compiling after `make peer` fails \"\n",
      "- \"2.12.0-rc0 logs JMX InstanceAlreadyExistsException at WARNING level\"\n",
      "- \"Support parallelCollectionScan command\"\n",
      "- \"DBRefBase should implement Serializable\"\n",
      "- \"Remove autoConnectRetry and maxAutoConnectRetryTime options\"\n",
      "- \"Remove support for w = -1\"\n",
      "- \"update description of fsync write concern flag\"\n",
      "- \"Allow acceptable latency difference to be configured via API\"\n",
      "- \"Deprecate com.mongodb.WriteResult#getLastError methods\"\n",
      "- \"Allow configuration of heartbeat background threads to be set via API\"\n",
      "- \"Improve scaffolder logging when yaml file is not valid\"\n",
      "- \"Scaffolder is not setting complete path for the resource\"\n",
      "- \"When generating a mule config file from scratch from yaml, the config-ref in the router is incorrect\"\n",
      "- \"Scaffolder cannot find included files in yaml\"\n",
      "- \"Generated flows don't have the correct indentation\"\n",
      "- \"Scaffolder is duplicating flows\"\n",
      "- \"scaffolder is not generating flows properly\"\n",
      "- \"yaml file generated with Maven archetype should have global tag set to tag:raml.org,0.1:\"\n",
      "- \"Update scaffolder mule config with latest changes\"\n",
      "- \"Create script to populate apikit dependences, archetype and maven plugin\"\n",
      "- \"Raml file created should have .yaml extension\"\n",
      "- \"Update archetype mule config with latest changes\"\n",
      "- \"Remove EE repositories from pom file generated with Maven archetype\"\n",
      "- \"mvn:apikit create - config file created should be included in mule-config.xml file\"\n",
      "- \"Maven archetype does not add port to http endpoint\"\n",
      "- \"Mule 3.2.1 HTTPS outbound endpoint leaking file descriptors\"\n",
      "- \"Bookstore example fails to show stats page\"\n",
      "- \"Inserting <collection-splitter /><collection-aggregator /> into a flow produces unexpected results\"\n",
      "- \"Add an extra information in the Issue Security documentation\"\n",
      "- \"Time Tracking Reports Documentation Outdated\"\n",
      "- \"Update JIRA REST documentation about removing a user from a project role\"\n",
      "- \"Update Creating Issue and Comments documentation\"\n",
      "- \"Application Documentation Error\"\n",
      "- \"Update Pie Chart Documentation for JIRA Server + Cloud\"\n",
      "- \"Upgrading JIRA Manually Instructions update suggestions\"\n",
      "- \"Releases notes for 6.1.2 should warn of ORA-01408 error on first start\"\n",
      "- \"Update JIRA REST documentation about setting users/groups to a project role\"\n",
      "- \"Update Configuring JIRA Options documentation regarding Gravatars\"\n",
      "- \"Link broken on Google Apps Integration FAQ\"\n",
      "- \"JQL documentation for searching Labels field\"\n",
      "- \"Update the recommendation for interim upgrade to any version below 4.3 go first to version 4.4.5\"\n",
      "- \"Modified the attachments query\"\n",
      "- \"Update instructions for installing on MAC OS X\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Complete all necessary tasks related to software development, documentation updates, and system deployment for the upcoming project milestones.\n",
      "Issue Titles:\n",
      "- \"All Hands\"\n",
      "- \"Create the pub sub program\"\n",
      "- \"Moving Work and logistics\"\n",
      "- \"Learn the Jenkins Robotframework Pipeline\"\n",
      "- \"Write setup.py for ts_sal\"\n",
      "- \"PCW 2019\"\n",
      "- \"Image display + File monitor integration\"\n",
      "- \"LSST 2019 meeting\"\n",
      "- \"Test and release SAL V4\"\n",
      "- \"Modify run_atdome.py to use the standard CSC main method\"\n",
      "- \"PCW2019 - Rob\"\n",
      "- \"Epic to track folks time at the PCE\"\n",
      "- \"AT Whitelight returns\"\n",
      "- \"ATHexapod update for salobj 4\"\n",
      "- \"Check the M2 MATLAB Tool\"\n",
      "- \"Design salobj to Kafka feeder\"\n",
      "- \"Attend the Project Community Workshop\"\n",
      "- \"Review the Documents of Hexapod and Rotator in Phase 2\"\n",
      "- \"Deploy simulators on ncsa-integration-test-stand\"\n",
      "- \"Write python mitutoyo gauge wrapper\"\n",
      "- \"Split develop-env-conda into two images\"\n",
      "- \"Write ts_idl conda recipe and setup.py\"\n",
      "- \"Write Watcher model\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Improve user experience by resolving inconsistencies in status coloration across different applications, ensuring that temporary files for the Atlassian Companion App are stored correctly outside the Roaming profile on Windows, and addressing the system clock error issue when starting the Companion App.\n",
      "Issue Titles:\n",
      "- \"Inconsistent status macro colours\"\n",
      "- \"Store temporary files for Atlassian Companion App outside of the Roaming profile on Windows\"\n",
      "- \"Companion App throws System clock error if it starts up before the computer has synced with the NTP server\"\n",
      "--------------------------------------------------\n",
      "Sprint Goal: Implement the feature allowing chaincode authors to securely initialize with their own private data.\n",
      "Issue Titles:\n",
      "- \"As a chaincode author, I want to set private data in chaincode Init()\"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print sprint goal and issue title pairs\n",
    "for _, row in sprint_training_df.iterrows():\n",
    "    print(f\"Sprint Goal: {row['sprint_goal']}\")\n",
    "    print(f\"Issue Titles:\\n{row['formatted_issues']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
